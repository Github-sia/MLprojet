{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2Dto3D.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Github-sia/MLprojet/blob/master/2Dto3D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcC2VG-uQJTG",
        "colab_type": "code",
        "outputId": "e8f49511-d283-4443-965c-6ffa8c4a32f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "!pip install face-alignment"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face-alignment\n",
            "  Downloading https://files.pythonhosted.org/packages/20/86/26baa3888c254c9ce284702a1041cf9a533ad91c873b06f74d3cfa23aff7/face_alignment-1.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from face-alignment) (4.38.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from face-alignment) (0.16.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from face-alignment) (1.4.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from face-alignment) (1.4.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from face-alignment) (4.1.2.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face-alignment) (1.18.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->face-alignment) (2.4)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->face-alignment) (7.0.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->face-alignment) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->face-alignment) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->face-alignment) (3.2.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->face-alignment) (4.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (46.0.0)\n",
            "Installing collected packages: face-alignment\n",
            "Successfully installed face-alignment-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GbwLWabS_MH",
        "colab_type": "code",
        "outputId": "319fb294-8139-4a80-c6aa-ca79a7e91478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!pwd\n",
        "!git clone https://github.com/Github-sia/MLprojet\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "fatal: destination path 'MLprojet' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EgqmXqlTGX3",
        "colab_type": "code",
        "outputId": "241c42e6-8ec9-4679-ba64-8eb4e261ed06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mMLprojet\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THtZZykSTkoa",
        "colab_type": "code",
        "outputId": "e53e1f43-43b3-44a9-cd9d-d28fb8fea4f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "cd MLprojet/\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'MLprojet/'\n",
            "/content/MLprojet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sXyshSJTp4g",
        "colab_type": "code",
        "outputId": "b7c8bf9f-517d-4de6-d92b-f9f11ecaae8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2Dto3D.ipynb  bface.jpg  \u001b[0m\u001b[01;34mdatasets\u001b[0m/  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfteT8s-XZb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import os\n",
        "from os import path\n",
        "import re\n",
        "from setuptools import setup, find_packages\n",
        "# To use consisten encodings\n",
        "from codecs import open\n",
        "\n",
        "# Function from: https://github.com/pytorch/vision/blob/master/setup.py\n",
        "\n",
        "\n",
        "def read(*names, **kwargs):\n",
        "    with io.open(\n",
        "        os.path.join(os.path.dirname(__file__), *names),\n",
        "        encoding=kwargs.get(\"encoding\", \"utf8\")\n",
        "    ) as fp:\n",
        "        return fp.read()\n",
        "\n",
        "# Function from: https://github.com/pytorch/vision/blob/master/setup.py\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Get the long description from the README file\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "requirements = [\n",
        "    'torch',\n",
        "    'numpy',\n",
        "    'scipy>=0.17',\n",
        "    'scikit-image',\n",
        "    'opencv-python',\n",
        "    'tqdm',\n",
        "    'enum34;python_version<\"3.4\"'\n",
        "]\n",
        "\n",
        "install_requires=requirements,\n",
        "license='BSD',\n",
        "zip_safe=True,\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRb04MQwKQZW",
        "colab_type": "code",
        "outputId": "926f597c-baab-4ae0-840e-c97a2e14c67c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "import face_alignment\n",
        "from skimage import io\n",
        "import torch \n",
        "import subprocess\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "from datetime import datetime\n",
        "import time\n",
        "import tensorflow as tf, sys\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow\n",
        "\n",
        "fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, flip_input=False, device = 'cpu')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading the Face Alignment Network(FAN). Please wait...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djHW0w_F87gI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = io.imread('bface.jpg')\n",
        "preds = fa.get_landmarks(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64sI4EpVUXUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id=0\n",
        "if preds is not None:\n",
        "  if len(preds)==1:\n",
        "    id=id+1\n",
        "    f= open('landM.pts',\"w+\")\n",
        "    f.write(\"version: 1\\n\")\n",
        "    f.write(\"n_points: 68\\n\")\n",
        "    f.write(\"{\\n\")\n",
        "    for i in range (0,len(preds[0])):\n",
        "      f.write(str(preds[0][i][0]) + \" \" + str(preds[0][i][0]) + \"\\n\")\n",
        "\n",
        "    f.write(\"}\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGyDBNypCBOc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f652c2f-afa5-4fb1-dc60-450607713c6d"
      },
      "source": [
        "ls\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2Dto3D.ipynb  bface.jpg  \u001b[0m\u001b[01;34mdatasets\u001b[0m/  landM.pts  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALUKbfWgB2cV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_pts(path):\n",
        "    \"\"\"takes as input the path to a .pts and returns a list of \n",
        "\ttuples of floats containing the points in in the form:\n",
        "\t[(x_0, y_0, z_0),\n",
        "\t (x_1, y_1, z_1),\n",
        "\t ...\n",
        "\t (x_n, y_n, z_n)]\"\"\"\n",
        "    with open(path) as f:\n",
        "        rows = [rows.strip() for rows in f]\n",
        "    \n",
        "    \"\"\"Use the curly braces to find the start and end of the point data\"\"\" \n",
        "    head = rows.index('{') + 1\n",
        "    tail = rows.index('}')\n",
        "\n",
        "    \"\"\"Select the point data split into coordinates\"\"\"\n",
        "    raw_points = rows[head:tail]\n",
        "    coords_set = [point.split() for point in raw_points]\n",
        "\n",
        "    \"\"\"Convert entries from lists of strings to tuples of floats\"\"\"\n",
        "    points = [tuple([float(point) for point in coords]) for coords in coords_set]\n",
        "    return points"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTAOHnVBWQKj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "2f8b1be3-697d-4ce7-b9a6-039589012d2b"
      },
      "source": [
        "\n",
        "landmark=read_pts(landM.pts)\n",
        "\n",
        "image = cv2.imread(bface.jpg)\n",
        "height, width = image.shape[:2]\n",
        "image_width = width\n",
        "image_height = height\n",
        "\n",
        "model = eos.morphablemodel.load_model(dirpath + \"/share/sfm_shape_3448.bin\")\n",
        "morphablemodelObj =eos.morphablemodel.MorphableModel(model.get_shape_model(), blendshapes,\n",
        "                                                     clor_model=eos.morphablemodel.PcaModel(),vertex_definitions=None, texture_coordinates=model.get_texture_coordinates())\n",
        "landmarkMapper = eos.core.LandmarkMapper(dirpath + '/share/ibug_to_sfm.txt')\n",
        "edgeTopology = eos.morphablemodel.load_edge_topology(dirpath + '/share/ibug_to_sfm.txt')\n",
        "modelContour = eos.fitting.ModelContour.load(dirpath + '/share/sfm_model_contours.json')\n",
        "(mesh, pose, shape_coeffs, blendshape_coeffs) = eos.fitiing.fit_shape_and_pose(morphablemodelObj, landmarks, landmarkMapper, image_width, image_height, edgeTopology, contourLandmarks, modelContour)\n",
        "isomapObj = eos.render.extract_texture(mesh, pose, image, compute_view_angle=True)\n",
        "isomapObj = cv2.transpose(isomapObj)\n",
        "\n",
        "if not os.path.exists(meshFilePath):\n",
        "  os.makedirs(meshFilePath)\n",
        "cv2.imwrite( meshFilePath + \"/\" + filename + \"_texture.isomap.png\" , isomapObj);\n",
        "eos.Core.write_obj(mesh,meshFilePath + \"/\" +filename + \".obj\")\n",
        "eos.core.write_textured_obj(mesh,meshFilePath + \"/\" + filename + \"_texture.obj\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-263c8355f45d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlandmark\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_pts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlandM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjpg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'landM' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGDk4pHgaD8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import import pywavefront\n",
        "scene = pywavefront.Wavefront(filepath)\n",
        "faceLength = getCordinates(scene,441,7,bFaceLength=True)\n",
        "forehead = getCordinates(scene,381,796)\n",
        "cheekboneWidth = getCordinates(scene,280,706)\n",
        "jawLineWidth = getCordinates(scene,338,755)\n",
        "chinwidth = getCordinates(scene,12,455)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfdlxadPbqdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('drive/My Drive/HairstyleRec/femaleData/FaceMeasurments.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7A-syptb-pJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X = df.values[:, 3:]\n",
        "Y = df.values[:, 2]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size = 0.2, random_state = 100)\n",
        "dcTree = DecisionTreeClassifier(criterion = \"entropy\", random_state = 42, max_depth=4, min_samples_leaf=1,max_leaf_nodes=5)\n",
        "dcTree.fit(X_train, Y_train)\n",
        "\n",
        "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4, max_features=Nonen max_leaf_nodes=5, min_impurity_decrease=0.0, min_impurity_split=None,min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=42, splitter='best')\n",
        "Y_pred = dcTree.predict(X_test)\n",
        "print (\"Accuracy is\", accuracy_score(Y_test,Y_pred)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMeMN-Izis4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q pydot\n",
        "import pands as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('drive/My Drive/HairStyleRec/femaleData/faceMeasurements.csv')\n",
        "X = df.values[:, 3:]\n",
        "Y = df.values[:, 2]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size = 0.2, random_state = 100)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "randClassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', max_depth=4, random_state=42)\n",
        "randClassifier.fit(X_train,Y_train)\n",
        "\n",
        "Y_pred = randClassifier.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY113oa6k2Fd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimator = randClassifier.estimators_[2]\n",
        "featureNames=['FaceLength','Forehead', 'CheekboneWidth', 'JawLineWidth', 'ChinWidth'];\n",
        "from sklearns.tree import export_graphviz\n",
        "export_graphviz(estimator, out_file='RandomForestTree.dot', feature_names = featureNames, class_names = classNames, rounded = True, proportion = False, precision = 3, filled = True)\n",
        "\n",
        "from subprocess import call\n",
        "call(['dot', '-Tpng', 'RandomForestTree.dot', '-o', 'randomTree.png', '-Gdpi=600' ])\n",
        "\n",
        "from IPython.display import Image\n",
        "Image(filename = 'randomTree.png')\n",
        "print(\"Saved as an image \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqWBXnIZoeG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "\n",
        "df = pd.read_csv('drive/My Drive/HairstyleRec/femaleData/faceMeasurements.csv')\n",
        "X = df.values[:, 3:8]\n",
        "Y = df.values[:, 2]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "svmClassifier = svm.SVC(kernel='linear')\n",
        "svmClassifier.fit(X_train,Y_train)\n",
        "\n",
        "Y_pred = svmClassifier.predict(X_test)\n",
        "print (\"Accuracy is\", metrics.accuracy_score(Y_test,Y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}